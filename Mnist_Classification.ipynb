{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mnist-Classification**"
      ],
      "metadata": {
        "id": "1jIEELGpl6Kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the libraries\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten"
      ],
      "metadata": {
        "id": "HyM2Khe0lPuU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loding the data set from the keras\n",
        "(x_train,ytrain),(x_test,ytest)=keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "ttW4Da3vlbEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a353dc9d-4936-4dfe-8cb9-733bd6fc3a3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shape fo the data set\n",
        "x_train.shape  # where the data is in the form of the 2 dimensional array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3Q6B69QmEdO",
        "outputId": "2340a6bd-fa1e-476e-fcf8-4053ce677cb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape # we have the 10000 in the test data set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8zbzOrbmbfO",
        "outputId": "5d99cbb6-b22f-4d43-a5e5-e103376edc78"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for the first array\n",
        "x_train[0] # it is in the form of the 28x28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "SuTg1b08ml6I",
        "outputId": "a79a8d00-7143-431c-e376-9ee831991864"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-e74c9211-39c3-4e59-a197-fafa68912cd5\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-e74c9211-39c3-4e59-a197-fafa68912cd5 button').onclick = (e) => {\n",
              "        document.querySelector('#id-e74c9211-39c3-4e59-a197-fafa68912cd5').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-e74c9211-39c3-4e59-a197-fafa68912cd5 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the ytrain data\n",
        "ytrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MnHBmQ_m_DQ",
        "outputId": "4532ed61-cd2d-430b-94d8-fcedc815f89b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to check the image from the ytrain\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[1]) # imshow is used to see the image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "E5WcYtptnVT5",
        "outputId": "0b5f533d-0a5b-4d9b-ce3f-438f25040d4e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c2d13d83a50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we need to make the all values in the same range\n",
        "x_train=x_train/255\n",
        "x_test=x_test/255 # this is  like the scaling the data the data values\n",
        "# which lies between the 1 abd the 0"
      ],
      "metadata": {
        "id": "MCHYDLiRnxby"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDOtZ3Pqouiz",
        "outputId": "49c48db7-6be9-410b-f645-af18eb80dc22"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model building**"
      ],
      "metadata": {
        "id": "yNSnxIUdpEVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model fitting\n",
        "model=Sequential()\n",
        "\n",
        "# here in this data set we have only one problem where the data is 28x28 array\n",
        "# we need to convert the data into the 1d array with the function Flatten\n",
        "\n",
        "model.add(Flatten(input_shape=(28,28))) # converting the Pixels into the single dimensional\n",
        "model.add(Dense(128,activation='relu')) # hidden layer\n",
        "model.add(Dense(10,activation='softmax')) # output layer\n",
        "\n",
        "# we cand add the layers in the hidden layer for the more and the best accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG69EFojp0C_",
        "outputId": "ad581c1a-92e4-49bd-da23-7a7c6d243496"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "BFwlhoCtq1-O",
        "outputId": "70a5f443-60b3-4467-9e68-e345f12d5f84"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> From the above we can see that the total 101,770 parameters that we need to train   \n",
        "--> The hidden layer cointains the `784x128=100,480` weights and the `128 biases`  \n",
        "-->In the input layer we have the 10 nodes beacause this is the multilayer perceptron"
      ],
      "metadata": {
        "id": "xrxmncp1q6L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the loss function\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"Adam\",metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1hL7Xoo_q5oj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model\n",
        "model.fit(x_train,ytrain,epochs=10,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzwLkrcAuarJ",
        "outputId": "3f98d689-afba-42f4-ba28-17f2440c6f56"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.4687 - val_accuracy: 0.9551 - val_loss: 0.1575\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9591 - loss: 0.1376 - val_accuracy: 0.9671 - val_loss: 0.1121\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9729 - loss: 0.0889 - val_accuracy: 0.9679 - val_loss: 0.1035\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0639 - val_accuracy: 0.9712 - val_loss: 0.0933\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0496 - val_accuracy: 0.9680 - val_loss: 0.1062\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0360 - val_accuracy: 0.9772 - val_loss: 0.0808\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0289 - val_accuracy: 0.9762 - val_loss: 0.0827\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0227 - val_accuracy: 0.9729 - val_loss: 0.1012\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0176 - val_accuracy: 0.9737 - val_loss: 0.0969\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0154 - val_accuracy: 0.9772 - val_loss: 0.0912\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c2d123631d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the weights of  the model\n",
        "model.layers[1].get_weights()"
      ],
      "metadata": {
        "id": "sfDI1uEyy6Mw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97bd8890-34dd-46c3-84dc-fec5178ad1d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.02945327, -0.03151079,  0.06523877, ..., -0.02422654,\n",
              "         -0.01990192, -0.04541698],\n",
              "        [-0.00325119, -0.01841254,  0.07451244, ..., -0.00563798,\n",
              "          0.04260428,  0.01873472],\n",
              "        [-0.02152426,  0.07337315,  0.0054007 , ..., -0.0431398 ,\n",
              "         -0.02493289,  0.0741862 ],\n",
              "        ...,\n",
              "        [ 0.05626141, -0.07904029, -0.08094844, ...,  0.02351889,\n",
              "          0.05374206, -0.0454709 ],\n",
              "        [ 0.05006001,  0.02369512, -0.04332982, ..., -0.02263355,\n",
              "         -0.00629862,  0.07152811],\n",
              "        [ 0.07907292,  0.07282384,  0.03225203, ..., -0.00614745,\n",
              "          0.08060858, -0.02657763]], dtype=float32),\n",
              " array([ 0.02125772, -0.07519662,  0.06913634, -0.09771587,  0.09413292,\n",
              "        -0.06190231, -0.07638967,  0.0502386 ,  0.07054266, -0.16695163,\n",
              "        -0.14409876,  0.09893368, -0.10169559, -0.17274497,  0.08828361,\n",
              "        -0.03663818,  0.0347662 ,  0.08042534,  0.00338305,  0.05333626,\n",
              "         0.02629961,  0.12448514, -0.02383161,  0.05415393,  0.10211239,\n",
              "         0.0859745 , -0.14024217,  0.06518381, -0.04336914,  0.01959571,\n",
              "         0.22164993, -0.05424142,  0.14160824,  0.03464716,  0.05763334,\n",
              "         0.1296167 ,  0.16500893, -0.06031084,  0.20990328,  0.06366854,\n",
              "        -0.00559556, -0.02642099,  0.20758042,  0.21975863,  0.16937852,\n",
              "        -0.13232918,  0.08250184,  0.01164945, -0.14689645, -0.13714632,\n",
              "         0.01674997,  0.08343552,  0.13900149,  0.09822971,  0.10192253,\n",
              "         0.04425772, -0.00756715, -0.07120772,  0.05429554,  0.0580647 ,\n",
              "         0.0238675 ,  0.0742171 ,  0.06749953, -0.00738171, -0.14870077,\n",
              "         0.03649481,  0.09513452,  0.1407223 ,  0.1936413 ,  0.05265978,\n",
              "         0.02349409,  0.03521025,  0.01132243, -0.02091714, -0.05082479,\n",
              "         0.03684847, -0.01594474,  0.3173945 ,  0.05545705,  0.07599963,\n",
              "         0.00828226, -0.10002267,  0.10819261, -0.1138896 ,  0.04304145,\n",
              "        -0.01709433, -0.10237134,  0.01625311,  0.19504595,  0.03574197,\n",
              "         0.02121074,  0.12540045, -0.07434049,  0.11320537,  0.06201476,\n",
              "        -0.13509825, -0.00413129, -0.07811466,  0.06312392,  0.10969795,\n",
              "        -0.09701962,  0.10414548,  0.08263124,  0.03839864, -0.00498368,\n",
              "         0.1036821 , -0.12623788,  0.02815543,  0.15369111, -0.07951922,\n",
              "         0.03915833, -0.01621732,  0.08174398, -0.1560342 ,  0.05101516,\n",
              "         0.04568272, -0.01344073,  0.05045467,  0.03489601, -0.03535033,\n",
              "        -0.12955798,  0.16260813,  0.01280988,  0.10247715,  0.09772842,\n",
              "        -0.00644742,  0.07633321,  0.06224579], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob=model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNhWCRxjzPti",
        "outputId": "b11172cd-cefa-4c26-b08f-907c345eb2ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=y_prob.argmax(axis=1)"
      ],
      "metadata": {
        "id": "zm6z4r8-zh80"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the accuracy of the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(ytest,y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADIzx2m50EG4",
        "outputId": "889b38f5-2f13-4023-f848-12a6b987daf8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9775"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> In the above we can add the hiddenlayers more for the best score here we are not going  with that because of the we got the better score which is the 97%  \n",
        "--> If we add the more layers unwantedly we can get the over fit in the data and  the model which reduce the score"
      ],
      "metadata": {
        "id": "RM-8LPV-1ZeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mnist.h5\")"
      ],
      "metadata": {
        "id": "ya31kIgGr8_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39c2225-b9b6-477e-f0be-843c0d6bea01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}